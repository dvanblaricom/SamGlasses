# Sam Glasses

A companion iOS app for Meta Ray-Ban smart glasses that connects to OpenClaw for AI-powered voice interactions.

## Overview

Sam Glasses enables hands-free AI conversations through Meta Ray-Ban smart glasses by leveraging:

- **OpenClaw**: AI gateway for chat completions, TTS, and Whisper transcription
- **Bluetooth HFP**: Audio routing through glasses microphone and speakers
- **Swift Concurrency**: Modern async/await patterns for seamless user experience
- **SwiftUI**: Native iOS interface with real-time status updates

## Features

### Current Features
- âœ… Voice-to-voice AI conversations via OpenClaw
- âœ… Bluetooth audio routing to Ray-Ban glasses
- âœ… On-device + cloud speech recognition (Apple Speech + OpenClaw Whisper)
- âœ… High-quality TTS via OpenClaw Edge TTS
- âœ… Real-time conversation history
- âœ… Secure auth token storage in Keychain
- âœ… Connection status monitoring

### Planned Features
- ğŸ”„ Camera capture and vision analysis (requires Meta DAT)
- ğŸ”„ Wake word detection
- ğŸ”„ Offline mode with cached conversations
- ğŸ”„ Multi-language support
- ğŸ”„ Custom voice commands and shortcuts

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SwiftUI App   â”‚    â”‚   Ray-Ban       â”‚    â”‚   OpenClaw      â”‚
â”‚                 â”‚    â”‚   Smart Glasses â”‚    â”‚   Gateway       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ MainView      â”‚    â”‚ â€¢ Microphone    â”‚    â”‚ â€¢ Chat API      â”‚
â”‚ â€¢ SettingsView  â”‚â—„â”€â”€â–ºâ”‚ â€¢ Speakers      â”‚â—„â”€â”€â–ºâ”‚ â€¢ TTS Service   â”‚
â”‚ â€¢ Status        â”‚    â”‚ â€¢ Bluetooth HFP â”‚    â”‚ â€¢ Whisper STT   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service Layer   â”‚    â”‚ Audio Pipeline  â”‚    â”‚ Network Layer   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ OpenClawClientâ”‚    â”‚ â€¢ AudioManager  â”‚    â”‚ â€¢ URLSession    â”‚
â”‚ â€¢ SpeechManager â”‚    â”‚ â€¢ AVAudioSessionâ”‚    â”‚ â€¢ Tailscale     â”‚
â”‚ â€¢ TTSManager    â”‚    â”‚ â€¢ AVAudioEngine â”‚    â”‚ â€¢ Auth Headers  â”‚
â”‚ â€¢ AudioManager  â”‚    â”‚ â€¢ HFP Routing   â”‚    â”‚ â€¢ Error Handlingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Setup Instructions

### Prerequisites

1. **Meta Ray-Ban Smart Glasses** with Bluetooth connectivity
2. **OpenClaw Gateway** running and accessible via Tailscale
3. **iOS Device** (iPhone/iPad) running iOS 15.2+
4. **Xcode 14+** for building the app

### Installation

1. **Clone and Build**
   ```bash
   cd /Users/dvbii/Development/SamGlasses
   open Package.swift  # Opens in Xcode
   ```

2. **Configure OpenClaw Gateway**
   - Ensure OpenClaw is running with Tailscale access
   - Note your gateway URL: `https://daves-mac-studio.taile75ef.ts.net`
   - Generate an auth token: `openclaw auth token`

3. **Pair Ray-Ban Glasses**
   - Enable Bluetooth on your iPhone
   - Pair glasses through Settings > Bluetooth
   - Ensure HFP (Hands-Free Profile) is connected

4. **App Configuration**
   - Launch Sam Glasses app
   - Open Settings (gear icon)
   - Enter your OpenClaw auth token
   - Verify connection status shows "Connected"
   - Grant microphone and speech recognition permissions

### Usage

1. **Basic Conversation**
   - Tap the blue "Tap to Talk" button
   - Speak your question/request
   - Tap "Stop Recording" when done
   - Listen to AI response through glasses speakers

2. **Quick Actions**
   - "Identify" - Ask "What am I looking at?" (vision placeholder)
   - "Ask" - Ask "What should I do next?"

3. **Settings**
   - Configure preferred TTS voice
   - Adjust speech rate
   - Choose on-device vs cloud speech recognition
   - Select audio device routing

## Development Notes

### Project Structure

```
Sources/SamGlasses/
â”œâ”€â”€ App/
â”‚   â””â”€â”€ SamGlassesApp.swift          # App entry point
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ OpenClawClient.swift         # Core API client
â”‚   â”œâ”€â”€ AudioManager.swift           # Bluetooth HFP audio
â”‚   â”œâ”€â”€ SpeechManager.swift          # Speech recognition
â”‚   â””â”€â”€ TTSManager.swift             # Text-to-speech
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ MainView.swift               # Primary interface
â”‚   â””â”€â”€ SettingsView.swift           # Configuration UI
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ ConversationMessage.swift    # Message data model
â””â”€â”€ Utilities/
    â””â”€â”€ KeychainHelper.swift         # Secure storage
```

### Key Components

- **OpenClawClient**: Central API client handling all OpenClaw communication
- **AudioManager**: Manages Bluetooth HFP routing to glasses
- **SpeechManager**: Dual-mode speech recognition (on-device + cloud)
- **TTSManager**: High-quality TTS with audio routing
- **KeychainHelper**: Secure credential storage

### Swift Patterns Used

- **@MainActor**: UI-safe async operations
- **@Observable / @StateObject**: Reactive data flow
- **async/await**: Modern concurrency throughout
- **Combine**: Publisher/subscriber for real-time updates
- **URLSession**: HTTP client with proper error handling

### API Endpoints

- **Chat Completions**: `POST /v1/chat/completions`
- **TTS**: `POST /tts` (assumed)
- **Whisper**: `POST /whisper` (assumed)
- **Health Check**: `GET /health` (assumed)

## Meta Ray-Ban Integration

### Audio Pipeline
1. **Recording**: Glasses mic â†’ Bluetooth HFP â†’ iOS AudioEngine
2. **Processing**: Audio data â†’ Speech recognition â†’ OpenClaw chat
3. **Response**: OpenClaw TTS â†’ iOS AudioSession â†’ Bluetooth HFP â†’ Glasses speakers

### Camera Integration (Future)
- Requires Meta DAT (Device Access Token)
- Will enable real-time vision analysis
- Image capture â†’ Base64 encoding â†’ OpenClaw vision model

## Troubleshooting

### Connection Issues
- Verify Tailscale connectivity: `ping daves-mac-studio.taile75ef.ts.net`
- Check OpenClaw service status
- Validate auth token with `openclaw auth whoami`

### Audio Issues
- Ensure Ray-Ban glasses are connected via Bluetooth
- Check HFP profile is active (not just A2DP)
- Verify microphone permissions granted
- Test with built-in iPhone audio first

### Speech Recognition Issues
- Grant Speech Recognition permission in iOS Settings
- Try toggling between on-device and cloud recognition
- Check internet connectivity for Whisper fallback
- Verify supported language selection

## Contributing

1. Follow Swift style guidelines
2. Use async/await for all async operations
3. Add comprehensive error handling
4. Write unit tests for service classes
5. Document public APIs with Swift DocC

## License

MIT License - See LICENSE file for details

## Support

- **Documentation**: [OpenClaw Docs](https://docs.openclaw.dev)
- **Issues**: GitHub Issues
- **Meta Ray-Ban**: [Meta Developer Portal](https://developers.meta.com)

---

*Built with â¤ï¸ for seamless AI-powered smart glasses experiences*